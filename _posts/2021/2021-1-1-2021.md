---
layout: post
title: '学习周报「2021」'
date: '2021-01-01 00:00'
category: 学习周报
tags: 学习周报 2021
author: lework
---
* content
{:toc}

> 以每周一个节点，记录知识点。




## 2021-01-4~10

### Exchange PowerShell 脚本 定时任务设置

```powershell
# 第一种
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe -ExecutionPolicy RemoteSigned -noprofile -noninteractive -file "E:\scripts\ExchangeDailyCheckList.ps1"

# 第二种
C:\Windows\system32\WindowsPowerShell\v1.0\powershell.exe -NonInteractive -WindowStyle Hidden -command ". 'C:\Program Files\Microsoft\Exchange Server\V15\bin\RemoteExchange.ps1'; Connect-ExchangeServer -auto; . E:\scripts\ExchangeDailyCheckList.ps1"
```



## 2021-01-11~17

### 通过 doh 方式获取域名解析

```bash
get_ip_from_doh() {
   local domain=${1:-www.baidu.com}
   local dohs=(doh.defaultroutes.de dns.hostux.net uncensored.lux1.dns.nixnet.xyz dns.rubyfish.cn dns.alidns.com doh.centraleu.pi-dns.com doh.dns.sb doh-fi.blahdns.com fi.doh.dns.snopyta.org dns.flatuslifir.is doh.li dns.digitale-gesellschaft.ch)
   ip=$(curl -4fsSLkA- -m200 "https://${dohs[$((RANDOM%10))]}/dns-query?name=${domain}" | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b" |tr ' ' '\n'|grep -Ev [.]0|sort -uR|head -1)
   echo "${domain}: ${ip}"
}
```

### [每日一问] k8s 集群什么条件下会产生endpoint 事件?

1.  创建 service，endpoint control 就会创建相应的endpoint，service匹配endpoint中的信息。

### kvm 镜像转 vmware esxi

1. 将kvm下虚拟机关机；

2. 将kvm下img文件格式的虚拟机转换成vmdk格式，命令如下：

   ```bash
   # 该命令只转换为vmware workstation的兼容.
   qemu-img convert -f qcow2 centos-t1.img -O vmdk centos-t1_temp.vmdk -o compat6 
   ```

3. 将镜像文件传递到 esxi 中

4. 转换esxi兼容的硬盘格式.

   ```bash
   # 转换为esxi兼容.
   vmkfstools -i myImage.vmdk outputName.vmdk -d thin
   ```

   > 注意这样转换出来的是两个文件：一个outputName.vmdk 是元数据，一个outputName-flat.vmdk是硬盘数据，二者必须保持一致的命名，如果要移动必须一起移动。不要自己给硬盘文件取名的时候在后面加-flat，这会导致问题。

5. 在 esxi 环境里创建一个虚拟机和kvm环境虚拟机配置相同，不用创建磁盘使用刚刚转换的vmdk文件，开启虚拟机即可.

   > 如果找不到启动项，请修改启动引导固件（Bios,EFI）然后在试试

## 2021-01-18~24

### 错误重试

重试：即从新尝试，以观察结果是否符合预期。

常见的重试策略：

1. 固定循环次数方式

   指定一个错误重试次数，当遇到错误时，不停的重试，直到次数用尽。

   这种方式的问题在于：不带backoff 的重试，对于下游来说会在失败发生时进一步遇到更多的请求压力，继而进一步恶化。

2. 带固定delay 的方式

   在失败之后，进行固定间隔的delay， delay 的方式按照是方法本身是异步还是同步的，可以通过定时器或则简单的Thread.sleep 实现。

   这种方式的问题在于：虽然这次带了固定间隔的backoff，但是每次重试的间隔固定，此时对于下游资源的冲击将会变成间歇性的脉冲；特别是当集群都遇到类似的问题时，步调一致的脉冲，将会最终对资源造成很大的冲击，并陷入失败的循环中。

3. 带随机delay 的方式

   和2 中固定间隔的delay 不一样，现在采用随机backoff 的方式，即具体的delay 时间，在一个最小值和最大值之间浮动。

   这种方式的问题在于：虽然现在解决了backoff 的时间集中的问题，对时间进行了随机打散，但是依然存在下面的问题：

   - 如果依赖的底层服务持续地失败，改方法依然会进行固定次数的尝试，并不能起到很好的保护作用。
   - 对结果是否符合预期，是否需要进行重试依赖于异常。
   - 无法针对异常进行精细化的控制，如只针部分异常进行重试

4. 可进行细粒度控制的重试

   一般这个时候，代码已经相对来说比较复杂了，个人推荐使用resilience4j-retr y 或则spring-retry 等库来进行组合，减少自己编写时维护成本，比如以resilience4j-retry 为例，其可以使用配置代码对重试策略进行细粒度的控制

   这种方式的问题在于：虽然可以比较好的控制重试策略，但是对于下游资源持续性的失败，依然没有很好的解决。当持续的失败时，对下游也会造成持续性的压力。一般这种问题的解法，我们日常工作中都是通过一个开关来进行人工断路，另一个比较好的解法是和断路器结合。

5. 和断路器结合

   在应用断路器时，需要对下游资源的每次调用都通过断路器，对代码具备一定的结构侵入性。
   常见的有Hystrix 或resilience4j

   当断路器处于开断状态时，所有的请求都会直接失败，不再会对下游资源造成冲击，并能够在一段时间后，进行探索式的尝试，如果没有达到条件，可以自动地恢复到之前的闭合状态。



**重试的一些其他实现**

对失败做出反应

在反应式宣言中，也有提到，对对失败做出反应，系统在遇到失败时，可以恢复，并隔离失败的组件，而不是不受控的失败。系统是否具备回弹性，对于线上正常安全生产有很大的影响。正确地实现“重试”，只是整个大图中非常小的一环，实际生产中还需要从架构、生产流程、编码细节处理，监控报警等多种手段入手。

失败（和“错误”相对照）

**失败是一种服务内部的意外事件**， 会阻止服务继续正常地运行。失败通常会阻止对于当前的、并可能所有接下来的客户端请求的响应。和错误相对照， **错误是意料之中的**，并且针各种情况进行了处理（ 例如， 在输入验证的过程中所发现的错误）， 将会作为该消息的正常处理过程的一部分返回给客户端。而失败是意料之外的， 并且在系统能够恢复至（和之前）相同的服务水平之前，需要进行干预。这并不意味着失败总是致命的（fatal）， 虽然在失败发生之后， 系统的某些服务能力可能会被降低。错误是正常操作流程预期的一部分， 在错误发生之后， 系统将会立即地对其进行处理， 并将继续以相同的服务能力继续运行。失败的例子有：硬件故障、由于致命的资源耗尽而引起的进程意外终止，以及导致系统内部状态损坏的程序缺陷。

回弹性

**回弹性是通过复制、遏制、隔离以及委托来实现的**。失败的扩散被遏制在了每个组件内部， 与其他组件相互隔离，从而确保系统某部分的失败不会危及整个系统，并能独立恢复。每个组件的恢复都被委托给了另一个（外部的）组件， 此外，在必要时可以通过复制来保证高可用性。（因此）组件的客户端不再承担组件失败的处理。

### CDN 工作原理

内容分发网络（Content Delivery Network，简称CDN）是建立并覆盖在承载网之上，由分布在不同区域的边缘节点服务器群组成的分布式网络。

CDN 应用广泛，支持多种行业、多种场景内容加速，例如：图片小文件、大文件下载、视音频点播、直播流媒体、全站加速、安全加速。

**简单介绍CDN 的工作原理：**

1. 当终端用户（北京）向www.a.com 下的指定资源发起请求时，首先向LDNS（本地D
NS）发起域名解析请求。
2. LDNS 检查缓存中是否有www.a.com 的IP 地址记录。如果有，则直接返回给终端用户；
如果没有，则向授权DNS 查询。
3. 当授权DNS 解析www.a.com 时，返回域名CNAME www.a.tbcdn.com 对应IP 地址。
4. 域名解析请求发送至阿里云DNS 调度系统，并为请求分配最佳节点IP 地址。
5. LDNS 获取DNS 返回的解析IP 地址。
6. 用户获取解析IP 地址。
7. 用户向获取的IP 地址发起对该资源的访问请求。
   - 如果该IP 地址对应的节点已缓存该资源，则会将数据直接返回给用户
   - 如果该IP 地址对应的节点未缓存该资源，则节点向源站发起对该资源的请求。获取资
     源后，结合用户自定义配置的缓存策略，将资源缓存至节点，并返回给用户，请求结束。

**淘宝图片空间和CDN 的架构**

淘宝整个图片的访问链路有三级缓存（客户端本地、CDN L1、CDN L2），所有图片都持久化的存储到OSS 中。真正处理图片的是img-picasso 系统，它的功能比较复杂，包括从OSS 读取文件，对图片尺寸进行缩放，编解码，所以机器成本比较高。

CDN 的缓存分成2 级，合理的分配L1 和L2 的比例，一方面，可以通过一致性hash 的手段，在同等资源的情况下，缓存更多内容，提升整体缓存命中率；另一方面，可以平衡计算和O，IO，充分利用不同配置的机器的能力。

![image-20210121110926926](/assets/images/2021/study/image-20210121110926926.png)

用户访问图片的过程如下：
1. 用户通过手机淘宝来搜索商品或者查看宝贝详情。
2. 详情/搜索/推荐通过调用商品中心返回商品的图片URL。
3. 客户端本地如果有该图片的缓存，则直接渲染图片，否则执行下一步。
4. 从CDN L1 回源图片，如果L1 有该图片的缓存，则客户端渲染图片，同时缓存到本地，如果L1 没有缓存，则执行下一步。
5. 从CDN L2 回源图片，如果L2 有该图片的缓存，则客户端渲染图片，同时CDN L1 及客户端缓存图片内容，如果CDN L2 没有缓存该图片，则执行下一步。
6. 从图片空间回源图片，图片空间会从OSS 拉取图片源文件，按要求进行尺寸缩放，然后执行编解码，返回客户端能够支持的图片内容，之后客户端就可以渲染图片，同时CDN 的L1、L2 以及客户端都会缓存图片内容。



客户端和服务器之间的流量被称为**南北流量**。简而言之，南北流量是·server《==》client流量。
不同服务器之间的流量与数据中心或不同数据中心之间的网络流被称为**东西流量**。简而言之，东西流量是server《==》server流量。



可观察性可以：

- 及时反馈异常或者风险使得开发人员可以及时关注、修复和解决问题（告警）；
- 出现问题时，能够帮助快速定位问题根源并解决问题，以减少服务损失（减损）；
- 收集并分析数据，以帮助开发人员不断调整和改善服务（持续优化）

可观察性的数据类型：

- 数据指标（Metrics）
- 应用日志（Access Logs）
- 分布式追踪（Distributed Traces）



## 2021-01-25~31

### curl 输出连接时间

```
curl -L --output /dev/null --silent --show-error \
  --write-out 'time_namelookup:        %{time_namelookup}\ntime_connect:       %{time_connect}\ntime_appconnect:    %{time_appconnect}\ntime_pretransfer:   %{time_pretransfer}\ntime_redirect:      %{time_redirect}\ntime_starttransfer: %{time_starttransfer}\n----------\ntime_total:         %{time_total}\n' \
  'https://www.baidu.com'
```

### 监控指标的制定

在制定监控指标时可以参考以下内容作为指导：

Google SRE 黄金指标(面向用户系统中最重要的衡量因素)
- 延迟(Latency)： 延迟是发送请求和接收响应所需的时间。
- 通讯量(Utilization)： 监控当前系统的流量，用户衡量服务的容量需求。
- 饱和度(Saturation)：衡量当前服务的饱和度。
- 错误(Errors)：监控当前系统所有发生的错误请求，衡量当前系统错误发生的速率。

Weave Cloud RED方法（微服务架构应用的监控和度量）
- (请求)速率(Rate)：服务每秒接收的请求数。
- (请求)错误(Errors )：每秒失败的请求数。
- (请求)耗时(Duration)：每个请求的耗时。

USE方法（系统性能）
- 使用率(Utilization)：关注系统资源的使用情况。 这里的资源主要包括但不限于：CPU，内存，网络，磁盘等等。100%的使用率通常是系统性能瓶颈的标志。
- 饱和度(Saturation)：例如CPU的平均运行排队长度，这里主要是针对资源的饱和度(注意，不同于4大黄金信号)。任何资源在某种程度上的饱和都可能导致系统性能的下降。
- 错误(Errors)：错误计数。





## 2021-02-01~07

### 创建一个istio管理的服务

1. 通过注入方式创建deployment

   ```bash
   cat app.deployment.yaml | istioctl kube-inject -f - | kubectl apply -f -
   ```

2. 创建服务的Service

   ```bash
   kubectl apply -f app.service.yaml
   ```

3. 创建网关

   ```bash
   kubectl apply -f app.gateway.yaml
   ```

4. 创建istio默认路由

   ```bash
   kubectl apply -f app.VirtualService.yaml
   ```

5. 创建客户端负载策略

   ```bash
   kubectl apply -f app.DestinationRule.yaml
   ```

6. 查看资源是否创建完成

   ```bash
   kubectl get svc,po,vs,dr
   ```

7. 测试应用，对服务发送请求。

   ```bash
   curl http://$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')/app/
   ```

![image-20210224134237224](/assets/images/2021/study/image-20210224134237224.png)



### istio注入

[sidecar](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#sidecar) 的注入过程都需要遵循如下步骤：

1. Kubernetes 需要了解待注入的 [sidecar](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#sidecar) 所连接的 [Istio](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio) 集群及其配置；
2. Kubernetes 需要了解待注入的 [sidecar](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#sidecar) 容器本身的配置，如镜像地址、启动参数等；
3. Kubernetes 根据 [sidecar](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#sidecar) 注入模板和以上配置填充 [sidecar](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#sidecar) 的配置参数，将以上配置注入到应用容器的一侧；

手动注入 sidecar。

```
i  istioctl kube-inject -f ${YAML_FILE} | kuebectl apply -f -
```

### 

流量镜像

复制的流量有些不同点

- host属性值的不同，而区别就是多了一个`“-shadow”`的后缀
- x-forwarded-for 多了gateway的ip地址

注入延迟

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings
spec:
  hosts:
  - ratings
  http:
  - fault:
      delay:
        percent: 100
        fixedDelay: 2s
    route:
    - destination:
        host: ratings
        subset: v1
```

请求延迟

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews
  http:
  - route:
    - destination:
        host: reviews
        subset: v2
    timeout: 0.5s
```

重试

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: httpbin-retries
spec:
  hosts:
  - httpbin
  http:
  - route:
    - destination:
        host: httpbin
    retries:
      attempts: 3
      perTryTimeout: 1s
      retryOn: 5xx
```

> 如果服务在 1 秒内没有返回正确的返回值，就进行重试，重试的条件为返回码为`5xx`，重试 3 次



熔断

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: httpbin
spec:
  host: httpbin
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 1
      http:
        http1MaxPendingRequests: 1
        maxRequestsPerConnection: 1
```

> 当并发的连接和请求数超过 1 个，熔断功能将会生效。



故障注入

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ratings-route
spec:
  hosts:
  - ratings.prod.svc.cluster.local
  http:
  - route:
    - destination:
        host: ratings.prod.svc.cluster.local
        subset: v1
    fault:
      abort:
        percentage:
          value: 0.1
        httpStatus: 400
```

> 对 `v1` 版本的 `ratings.prod.svc.cluster.local` 服务访问的时候进行故障注入，`0.1`表示有千分之一的请求被注入故障， `400` 表示故障为该请求的 HTTP 响应码为 `400` 

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews-route
spec:
  hosts:
  - reviews.prod.svc.cluster.local
  http:
  - match:
    - sourceLabels:
        env: prod
    route:
    - destination:
        host: reviews.prod.svc.cluster.local
        subset: v1
    fault:
      delay:
        percentage:
          value: 0.1
        fixedDelay: 5s
```

> 对 `v1` 版本的 `reviews.prod.svc.cluster.local` 服务访问的时候进行延时故障注入，`0.1` 表示有千分之一的请求被注入故障，`5s` 表示`reviews.prod.svc.cluster.local` 延时 `5s`返回





### istio api 接口

```
http://istiod:15000/listeners  监控地址
http://istiod:15000/config_dump  获取配置
```

```
# 诊断网格配置
istioctl analyze
istioctl analyze -k --all-namespaces
istioctl analyze -k --all-namespaces --suppress "IST0102=Namespace frod"

# 检查网格中所有配置同步状态
istioctl ps

# 检查 Envoy 和 istiod 间的配置差异
istioctl ps reviews-v3-5f7b9f4f77-ttmhv.default   

# 查看指定 pod 的网格配置详情
istioctl pc cluster reviews-v3-5f7b9f4f77-ttmhv.default
istioctl pc cluster reviews-v3-5f7b9f4f77-ttmhv.default --port 9080 --direction inbound -o json

# 验证网格配置
istioctl experimental describe pod details-v1-79c697d759-vlsds.default
istioctl x describe pod details-v1-79c697d759-vlsds.default
```

xDS API：

| 服务简写 |                             全称                             |                 描述                  |
| :------: | :----------------------------------------------------------: | :-----------------------------------: |
|   LDS    | Listener Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |            监听器发现服务             |
|   RDS    | Route Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |             路由发现服务              |
|   CDS    | [Cluster](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#cluster) Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |             集群发现服务              |
|   EDS    | Endpoint Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |           集群成员发现服务            |
|   SDS    | [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) | v1 时的集群成员发现服务，后改名为 EDS |
|   ADS    | Aggregated Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |             聚合发现服务              |
|   HDS    | Health Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |            健康度发现服务             |
|   SDS    | Secret Discovery [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |             密钥发现服务              |
|    MS    | Metric [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |             指标发现服务              |
|   RLS    | Rate Limit [Service](https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service) |             限流发现服务              |
|   xDS    |                                                              |          以上各种 API 的统称          |

### istio sidecar流量劫持

![image-20210125154745297](/assets/images/2021/study/image-20210125154745297.png)



Gateway 是用于控制南北流量的网关，将 VirtualService 绑定到 Gateway 上，可以控制进入的 HTTP/TCP 流量。通过使用 ServiceEntry，可以使网格内部的服务正常发现和路由到外部服务，并在此基础上，结合 VirtualService 实现请求超时、故障注入等功能。

### istio 和 linkerd 对比

![image-20210207171150489](/assets/images/2021/study/image-20210207171150489.png)



## 2021-02-18~21

### Kubernetes api resources

![img](https://user-images.githubusercontent.com/5445356/105966980-47d41200-60c0-11eb-841f-b43929b820f8.png)

> https://twitter.com/iximiuz/status/1353045442087571456



### istio网络问题

1. Envoy 启动后会通过 xDS 协议向 pilot 请求服务和路由配置信息，Pilot 收到请求后会根据 Envoy 所在的节点（pod或者VM）组装配置信息，包括 Listener、Route、Cluster等，

2. 然后再通过 xDS 协议下发给 Envoy。
3. 根据 Mesh 的规模和网络情况，该配置下发过程需要数秒到数十秒的时间。
4. 由于初始化容器已经在 pod 中创建了 Iptables rule 规则，因此这段时间内应用向外发送的网络流量会被重定向到 Envoy ，而此时 Envoy 中尚没有对这些网络请求进行处理的监听器和路由规则，无法对此进行处理，导致网络请求失败。



#### 在应用启动命令中判断 Envoy 初始化状态

最直接的解决思路就是：在应用进程启动时判断 Envoy sidecar 的初始化状态，待其初始化完成后再启动应用进程。

Envoy 的健康检查接口 `localhost:15020/healthz/ready` 会在 xDS 配置初始化完成后才返回 200，否则将返回 503，因此可以根据该接口判断 Envoy 的配置初始化状态，待其完成后再启动应用容器。我们可以在应用容器的启动命令中加入调用 Envoy 健康检查的脚本，如下面的配置片段所示。在其他应用中使用时，将 `start-awesome-app-cmd` 改为容器中的应用启动命令即可。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: awesome-app-deployment
spec:
  selector:
    matchLabels:
      app: awesome-app
  replicas: 1
  template:
    metadata:
      labels:
        app: awesome-app
    spec:
      containers:
      - name: awesome-app
        image: awesome-app
        ports:
        - containerPort: 80
        command: ["/bin/bash", "-c"]
        args: ["while [[ \"$(curl -s -o /dev/null -w ''%{http_code}'' localhost:15020/healthz/ready)\" != '200' ]]; do echo Waiting for Sidecar;sleep 1; done; echo Sidecar available; start-awesome-app-cmd"]
```

该流程的执行顺序如下：

1. Kubernetes 启动 应用容器。
2. 应用容器启动脚本中通过 `curl get localhost:15020/healthz/ready` 查询 Envoy sidcar 状态，由于此时 Envoy sidecar 尚未就绪，因此该脚本会不断重试。
3. Kubernetes 启动 Envoy sidecar。
4. Envoy sidecar 通过 xDS 连接 Pilot，进行配置初始化。
5. 应用容器启动脚本通过 Envoy sidecar 的健康检查接口判断其初始化已经完成，启动应用进程。

#### 通过 pod 容器启动顺序进行控制

Kubernetes 会在启动容器后调用该容器的 postStart hook，postStart hook 会阻塞 pod 中的下一个容器的启动，直到 postStart hook 执行完成。因此如果在 Envoy sidecar 的 postStart hook 中对 Envoy 的配置初始化状态进行判断，待完成初始化后再返回，就可以保证 Kubernetes 在 Envoy sidecar 配置初始化完成后再启动应用容器。该流程的执行顺序如下：

1. Kubernetes 启动 Envoy sidecar 。
2. Kubernetes 执行 postStart hook。
3. postStart hook 通过 Envoy 健康检查接口判断其配置初始化状态，直到 Envoy 启动完成 。
4. Kubernetes 启动应用容器。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sidecar-starts-first
spec:
  containers:
  - name: istio-proxy
    image: 
    lifecycle:
      postStart:
        exec:
          command:
          - pilot-agent
          - wait
  - name: application
    image: my-application
```

该解决方案对 Kubernetes 有两个隐式依赖条件：

1. Kubernetes 在一个线程中按定义顺序依次启动 pod 中的多个容器
2. 以及前一个容器的 postStart hook 执行完毕后再启动下一个容器。

这两个前提条件在目前的 Kuberenetes 代码实现中是满足的，但由于这并不是 Kubernetes的 API 规范，因此该前提在将来 Kubernetes 升级后很可能被打破，导致该问题再次出现。



### istio 无头服务问题

#### 问题1:

问题现状：从带 Envoy Sidecar 的 Pod 中不能访问 Redis 服务器，但在没有安装 Sidecar 的 Pod 中可以正常访问该 Redis 服务器。

问题原因：问题是由于 Istio 1.6 版本前对 Headless Service 处理的一个 Bug，客户端的 Envoy 采用 mTLS 方式向只支持plain TCP服务器端发起连接， 从而导致无法连接。

解决方式：可以通过创建Destination Rule 禁用 Headless Service 的 mTLS 来规避该问题。

#### 问题2:

问题现状:  在 Spring Cloud 应用迁移到 Istio 中后，服务提供者向 Eureka Server 发送心跳失败。

问题原因： Envoy Cluster 的默认类型为 “ORIGINAL_DST”，该选项表明 Enovy 在转发请求时会直接采用 downstream 原始请求中的地址。在这种情况下，当 Pod 的 IP 变化后，Envoy 并不会立即主动断开和 Client 端的链接。此时从 Client 的角度来看，到 Pod 的 TCP 链接依然是正常的，因此 Client 会继续使用该链接发送 HTTP 请求。同时由于 Cluster 类型为 “ORIGINAL_DST” ，Envoy 会继续尝试连接 Client 请求中的原始目地地址 POD IP。但是由于该 IP 上的 Pod 已经被销毁，Envoy 会连接失败，并在失败后向 Client 端返回一个这样的错误信息：“upstream connect error or disconnect/reset before headers. reset reason: connection failure HTTP/1.1 503” 。

问题解决：  Envoy Cluster 类型修改为 EDS （Endopoint Discovery Service），普通服务采用 EDS 服务发现，根据 LB 算法从 EDS 下发的 endpoint 中选择一个进行连接。有状态的应用需要关闭envoy注入，以避免集群同步错误。



###  kubernetes 中主要使用到的证书

![img](https://zhaohuabing.com/img/2020-05-19-k8s-certificate/kubernetes-certificate-usage.png)上图中使用序号对证书进行了标注。图中的箭头表明了组件的调用方向，箭头所指方向为服务提供方，另一头为服务调用方。为了实现 TLS 双向认证，服务提供方需要使用一个服务器证书，服务调用方则需要提供一个客户端证书，并且双方都需要使用一个 CA 证书来验证对方提供的证书。为了简明起见，上图中只标注了证书使用方提供的证书，并没有标注证书的验证方验证使用的 CA 证书。图中标注的这些证书的作用分别如下：

1. etcd 集群中各个节点之间相互通信使用的证书。由于一个 etctd 节点既为其他节点提供服务，又需要作为客户端访问其他节点，因此该证书同时用作服务器证书和客户端证书。
2. etcd 集群向外提供服务使用的证书。该证书是服务器证书。
3. kube-apiserver 作为客户端访问 etcd 使用的证书。该证书是客户端证书。
4. kube-apiserver 对外提供服务使用的证书。该证书是服务器证书。
5. kube-controller-manager 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书。
6. kube-scheduler 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书。
7. kube-proxy 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书。
8. kubelet 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书。
9. 管理员用户通过 kubectl 访问 kube-apiserver 使用的证书,该证书是客户端证书。
10. kubelet 对外提供服务使用的证书。该证书是服务器证书。
11. kube-apiserver 作为客户端访问 kubelet 采用的证书。该证书是客户端证书。
12. kube-controller-manager 用于生成和验证 service-account token 的证书。该证书并不会像其他证书一样用于身份认证，而是将证书中的公钥/私钥对用于 service account token 的生成和验证。kube-controller-manager 会用该证书的私钥来生成 service account token，然后以 secret 的方式加载到 pod 中。pod 中的应用可以使用该 token 来访问 kube-apiserver， kube-apiserver 会使用该证书中的公钥来验证请求中的 token。我们将在文中稍后部分详细介绍该证书的使用方法。

**etcd 证书配置**

```bash
/usr/local/bin/etcd \\
  --cert-file=/etc/etcd/kube-etcd.pem \\                   # 对外提供服务的服务器证书
  --key-file=/etc/etcd/kube-etcd-key.pem \\                # 服务器证书对应的私钥
  --peer-cert-file=/etc/etcd/kube-etcd-peer.pem \\         # peer 证书，用于 etcd 节点之间的相互访问
  --peer-key-file=/etc/etcd/kube-etcd-peer-key.pem \\      # peer 证书对应的私钥
  --trusted-ca-file=/etc/etcd/cluster-root-ca.pem \\       # 用于验证访问 etcd 服务器的客户端证书的 CA 根证书
  --peer-trusted-ca-file=/etc/etcd/cluster-root-ca.pem\\   # 用于验证 peer 证书的 CA 根证书
```

**kubeapiserver 证书配置**

```bash
/usr/local/bin/kube-apiserver \\ 
  --tls-cert-file=/var/lib/kubernetes/kube-apiserver.pem \\                             # 用于对外提供服务的服务器证书
  --tls-private-key-file=/var/lib/kubernetes/kube-apiserver-key.pem \\                  # 服务器证书对应的私钥
  --etcd-certfile=/var/lib/kubernetes/kube-apiserver-etcd-client.pem \\                 # 用于访问 etcd 的客户端证书
  --etcd-keyfile=/var/lib/kubernetes/kube-apiserver-etcd-client-key.pem \\              # 用于访问 etcd 的客户端证书的私钥
  --kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver-kubelet-client.pem \\ # 用于访问 kubelet 的客户端证书
  --kubelet-client-key=/var/lib/kubernetes/kube-apiserver-kubelet-client-key.pem \\     # 用于访问 kubelet 的客户端证书的私钥
  --client-ca-file=/var/lib/kubernetes/cluster-root-ca.pem \\                           # 用于验证访问 kube-apiserver 的客户端的证书的 CA 根证书
  --etcd-cafile=/var/lib/kubernetes/cluster-root-ca.pem \\                              # 用于验证 etcd 服务器证书的 CA 根证书  
  --kubelet-certificate-authority=/var/lib/kubernetes/cluster-root-ca.pem \\            # 用于验证 kubelet 服务器证书的 CA 根证书
  --service-account-key-file=/var/lib/kubernetes/service-account.pem \\                 # 用于验证 service account token 的公钥
  ...
```

**kubeconfig里的证书配置**

```yaml
apiVersion: v1
clusters:
- cluster: 
    # 用于验证 kube-apiserver 服务器证书的 CA 根证书 
    certificate-authority-data: ...省略...
    server: https://localhost:8443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: system:kube-controller-manager
  name: system:kube-controller-manager@kubernetes
current-context: system:kube-controller-manager@kubernetes
kind: Config
preferences: {}
users:
- name: system:kube-controller-manager
  user:
    # 用于访问 kube-apiserver 的客户端证书
    client-certificate-data: ...省略...
    # 客户端证书对应的私钥
    client-key-data: ...省略...
```

**Service Account 证书**

 service account 主要被 pod 用于访问 kube-apiserver。 在为一个 pod 指定了 service account 后，kubernetes 会为该 service account 生成一个 JWT token，并使用 secret 将该 service account token 加载到 pod 上。pod 中的应用可以使用 service account token 来访问 api server。service account 证书被用于生成和验证 service account token。该证书的用法实际上使用的是其公钥和私钥，而并不需要对证书进行验证。

```bash
/usr/local/bin/kube-apiserver \\ 
  --service-account-key-file=/var/lib/kubernetes/service-account.pem \\          # 用于验证 service account token 的公钥
  ...
  
 /usr/local/bin/kube-controller-manager \\
 --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem  # 用于对 service account token 进行签名的私钥
 ... 
```

下图展示了 kubernetes 中生成、使用和验证 service account token 的过程。

![img](https://zhaohuabing.com/img/2020-05-19-k8s-certificate/service-account-token.png)

**Kubernetes 证书签发**

Kubernetes 提供了一个 `certificates.k8s.io` API，可以使用配置的 CA 根证书来签发用户证书。该 API 由 kube-controller-manager 实现，其签发证书使用的根证书在下面的命令行中进行配置。我们希望 Kubernetes 采用集群根 CA 来签发用户证书，因此在 kube-controller-manager 的命令行参数中将相关参数配置为了集群根 CA。

```bash
 /usr/local/bin/kube-controller-manager \\
 --cluster-signing-cert-file=/var/lib/kubernetes/cluster-root-ca.pem             # 用于签发证书的 CA 根证书
 --cluster-signing-key-file=/var/lib/kubernetes/cluster-root-ca-key.pem          # 用于签发证书的 CA 根证书的私钥  
 ... 
```

**使用 TLS bootstrapping 简化 Kubelet 证书制作**

Kubernetes 提供了 [TLS bootstrapping ](https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/)的方式来简化 Kubelet 证书的生成过程。其原理是预先提供一个 bootstrapping token，kubelet 采用该 bootstrapping token 进行客户端验证，调用 kube-apiserver 的证书签发 API 来生成 自己需要的证书。要启用该功能，需要在 kube-apiserver 中启用 `--enable-bootstrap-token-auth` ，并创建一个 kubelet 访问 kube-apiserver 使用的 bootstrap token secret。如果使用 kubeadmin 安装，可以使用 `kubeadm token create`命令来创建 token。

采用TLS bootstrapping 生成证书的流程如下：

1. 调用 kube-apiserver 生成一个 bootstrap token。
2. 将该 bootstrap token 写入到一个 kubeconfig 文件中，作为 kubelet 调用 kube-apiserver 的客户端验证方式。
3. 通过 `--bootstrap-kubeconfig` 启动参数将 bootstrap token 传递给 kubelet 进程。
4. Kubelet 采用bootstrap token 调用 kube-apiserver API，生成自己所需的服务器和客户端证书。
5. 证书生成后，Kubelet 采用生成的证书和 kube-apiserver 进行通信，并删除本地的 kubeconfig 文件，以避免 bootstrap token 泄漏风险。

###  Istio 证书分发流程

![img](https://zhaohuabing.com/img/2020-05-25-istio-certificate/istio-ca.svg)

1. Envoy 向 pilot-agent 发起一个 SDS (Secret Discovery Service) 请求，要求获取自己的证书和私钥。
2. Pilot-agent 生成私钥和 CSR （Certificates Signing Request，证书签名请求），向 Istiod 发送证书签发请求，请求中包含 CSR 和该 pod 中服务的身份信息。
3. Istiod 根据请求中服务的身份信息（Service Account）为其签发证书，将证书返回给 Pilot-agent。
4. Pilot-agent 将证书和私钥通过 SDS 接口返回给 Envoy。

Istio 数据面使用到的所有证书

![img](https://zhaohuabing.com/img/2020-05-25-istio-certificate/bookinfo-ca.svg)



### Nginx Ingress 高并发实践

系统内核调整

1. 调大连接队列的大小

   进程监听的 socket 的连接队列最大的大小受限于内核参数 `net.core.somaxconn`，在高并发环境下，如果队列过小，可能导致队列溢出，使得连接部分连接无法建立。backlog 在 linux 上默认为 511。 Nginx 监听 socket 时没有读取 somaxconn，而是有自己单独的参数配置。如下配置

   ```
   server {    
     listen  80  backlog=1024;
     ...
   ```

   Nginx Ingress Controller 会自动读取 linux的somaxconn 的值作为 backlog 参数写到生成的 nginx.conf 中，所以设置系统内核参数就可以了。

   ```
   sysctl -w net.core.somaxconn=65535
   ```

2. 扩大源端口范围

   在高并发环境下，端口范围小容易导致源端口耗尽，使得部分连接异常。建议调整为 1024-65535: `sysctl -w net.ipv4.ip_local_port_range="1024 65535"`

3. TIME_WAIT 复用

   如果短连接并发量较高，它所在 netns 中 TIME_WAIT 状态的连接就比较多，而 TIME_WAIT 连接默认要等 2MSL 时长才释放，长时间占用源端口，当这种状态连接数量累积到超过一定量之后可能会导致无法新建连接。

   建议给 Nginx Ingress 开启 TIME_WAIT 重用，即允许将 TIME_WAIT 连接重新用于新的 TCP 连接：`sysctl -w net.ipv4.tcp_tw_reuse=1`

4. 调大最大文件句柄数

   Nginx 作为反向代理，对于每个请求，它会与 client 和 upstream server 分别建立一个连接，即占据两个文件句柄，所以理论上来说 Nginx 能同时处理的连接数最多是系统最大文件句柄数限制的一半。

   系统最大文件句柄数由 `fs.file-max` 这个内核参数来控制，建议调大：`sysctl -w fs.file-max=1048576`。

通过 initContainers修改 nginx ingress 容器的内核参数

```yaml
      initContainers:
      - name: setsysctl
        image: busybox
        securityContext:
          privileged: true
        command:
        - sh
        - -c
        - |
          sysctl -w net.core.somaxconn=65535
          sysctl -w net.ipv4.ip_local_port_range="1024 65535"
          sysctl -w net.ipv4.tcp_tw_reuse=1
          sysctl -w fs.file-max=1048576
		securityContext:
            capabilities:
              add:
                - SYS_ADMIN
              drop:
                - ALL
```

```
			- /bin/sh
            - '-c'
            - |
              mount -o remount rw /proc/sys
              sysctl -w net.core.somaxconn=65535
              sysctl -w net.ipv4.ip_local_port_range="1024 65535"
              sysctl -w fs.file-max=1048576
              sysctl -w fs.inotify.max_user_instances=16384
              sysctl -w fs.inotify.max_user_watches=524288
              sysctl -w fs.inotify.max_queued_events=16384
```



nginx 配置调整

1. 调高 keepalive 连接最大请求数

   ginx 针对 client 和 upstream 的 keepalive 连接，均有 keepalive_requests 这个参数来控制单个 keepalive 连接的最大请求数，且默认值均为 100。当一个 keepalive 连接中请求次数超过这个值时，就会断开并重新建立连接。通过下列配置，调高默认值。

   ```
   keepalive_requests 10000
   ```

2. 调高 keepalive 最大空闲连接数

   它的默认值为 320，在高并发下场景下会产生大量请求和连接，而现实世界中请求并不是完全均匀的，有些建立的连接可能会短暂空闲，而空闲连接数多了之后关闭空闲连接，就可能导致 Nginx 与 upstream 频繁断连和建连，引发 TIME_WAIT 飙升。在高并发场景下可以调到 1000.

   ```
   keepalive 1000
   ```

3. 调高单个 worker 最大连接数

   `max-worker-connections` 控制每个 worker 进程可以打开的最大连接数，默认 16384，在高并发环境建议调高，比如设置到 65536，这样可以让 nginx 拥有处理更多连接的能力。

   ```
   worker_connections 65536
   ```

Nginx 全局配置通过 configmap 配置（Nginx Ingress Controller 会 watch 并自动 reload 配置）：

 ```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-ingress-controller
# nginx ingress 性能优化: https://www.nginx.com/blog/tuning-nginx/
data:
  # nginx 与 client 保持的一个长连接能处理的请求数量，默认 100，高并发场景建议调高。
  # 参考: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#keep-alive-requests
  keep-alive-requests: "10000"
  # nginx 与 upstream 保持长连接的最大空闲连接数 (不是最大连接数)，默认 320，在高并发下场景下调大，避免频繁建联导致 TIME_WAIT 飙升。
  # 参考: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-connections
  upstream-keepalive-connections: "1000"
  # 每个 worker 进程可以打开的最大连接数，默认 16384。
  # 参考: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
  max-worker-connections: "65536"
 ```



### k8s中，什么情况下驱逐会导致服务不可用？

1. 服务存在单点故障，所有副本都在同一个节点，驱逐该节点时，就可能造成服务不可用。
2. 服务没有单点故障，但刚好这个服务涉及的 Pod 全部都部署在这一批被驱逐的节点上，所以这个服务的所有 Pod 同时被删，也会造成服务不可用。
3. 服务没有单点故障，也没有全部部署到这一批被驱逐的节点上，但驱逐时造成这个服务的一部分 Pod 被删，短时间内服务的处理能力下降导致服务过载，部分请求无法处理，也就降低了服务可用性。

针对第一点，我们可以使用反亲和性来避免单点故障。

针对第二和第三点，我们可以通过配置 PDB (PodDisruptionBudget) 来避免所有副本同时被删除，驱逐时 K8S 会 "观察" nginx 的当前可用与期望的副本数，根据定义的 PDB 来控制 Pod 删除速率，达到阀值时会等待 Pod 在其它节点上启动并就绪后再继续删除，以避免同时删除太多的 Pod 导致服务不可用或可用性降低，下面给出两个示例。

示例一 (保证驱逐时 nginx 至少有 90% 的副本可用):

```yaml
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: k8s-app
            operator: In
            values:
            - kube-dns
      topologyKey: kubernetes.io/hostname
```

示例二 (保证驱逐时 zookeeper 最多有一个副本不可用，相当于逐个删除并等待在其它节点完成重建):

```yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: zk-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: zookeeper
```



### k8s 节点升级注意事项

1. 在滚动升级的时候，涉及到网络组件，dns组件，istio组件驱逐的时候，会有一段时间访问不可用。
2. 没有配置反亲和性的deployment，在配置中断预算后，会导致驱逐失败，从而卡住升级流程。在没有配置中断预算后，会导致服务在一定时间内全部不可用。
3. 在没有充足的资源预留，会导致升级节点的pod处于pending状态。


解决办法
1. 资源预留充足，保障能接收驱逐节点的pod资源，提前 pull 驱逐节点的镜像资源，减少启动时间。
2. 设置关键组件的反亲和性，避免多个pod处于一个节点上。
3. 设置关键组件的中断预算，避免服务完全不可用。
4. 关键组件手动调度，避免使用驱逐命令统一驱逐。
5. dns解析失败，可使用nodelocaldns组件在节点上缓存和代理解析，避免dns pod更换ip时，客户端解析出现异常。



### Kafka丢消息的处理

![img](https://blackdog.oss-cn-qingdao.aliyuncs.com/blog/kfk-lost-1.jpg/s)

> https://blog.dogchao.cn/?p=305



## 2021-02-22~28


### k8s api server 限流

- MaxInFlightLimit，server级别整体限流
- Client限流
- EventRateLimit, 限制event
- APF，更细力度的限制配置

> https://qingwave.github.io/k8s-rate-limit/

### Ingress获取真实IP

1. use-forwarded-headers

    ```yaml
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: nginx-configuration
    data:
      compute-full-forwarded-for: 'true'
      use-forwarded-headers: 'true'
    ```

2. 使用 real_ip_header

   ```
   kind: ConfigMap
   apiVersion: v1
   metadata:
     name: nginx-configuration
   data:
     http-snippet: |
       real_ip_header X-Forwarded-For;
   ```

3. golang中获取真实ip

   ```go
   func RemoteIP(r *http.Request) string {
     // ingress 行为，将真实ip放到header `X-Original-Forwarded-For`, 普通nginx可去掉此条
       ip := strings.TrimSpace(strings.Split(r.Header.Get("X-Original-Forwarded-For"), ",")[0])
       if ip != "" {
           return ip
       }
   
       ip = strings.TrimSpace(strings.Split(r.Header.Get("X-Forwarded-For"), ",")[0])
       if ip != "" {
           return ip
       }
   
       ip = strings.TrimSpace(r.Header.Get("X-Real-Ip"))
       if ip != "" {
           return ip
       }
   
       if ip, _, err := net.SplitHostPort(strings.TrimSpace(r.RemoteAddr)); err == nil {
           return ip
       }
   
       return ""
   }
   ```

   

### 快速进入容器命名空间
{% raw %}
```bash
function e() {
  # 快速进入容器命名空间
  # exp: e POD_NAME NAMESPACE
  set -eu
  pod_name=${1}
  ns=${2-"default"}
  host_ip=$(kubectl -n $ns get pod $pod_name -o jsonpath='{.status.hostIP}')
  container_id=$(kubectl -n $ns describe pod $pod_name | grep -A10 "^Containers:" | grep -Eo 'docker://.*$' | head -n 1 | sed 's/docker:\/\/\(.*\)$/\1/')
  container_pid=$(docker inspect -f {{.State.Pid}} $container_id)
  cmd="nsenter -n --target $container_pid"
  echo "entering pod netns for [${host_ip}] $ns/$pod_name"
  echo $cmd
  $cmd
}
```
{% endraw %}


### 保留Exit Code 

| Exit Code Number | Meaning                                                      | Example                     | Comments                                                     |
| ---------------- | ------------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| `1`              | Catchall for general errors                                  | let "var1 = 1/0"            | Miscellaneous errors, such as "divide by zero" and other impermissible operations |
| `2`              | Misuse of shell builtins (according to Bash documentation)   | empty_function() {}         | [Missing keyword](https://tldp.org/LDP/abs/html/debugging.html#MISSINGKEYWORD) or command, or permission problem (and [*diff* return code on a failed binary file comparison](https://tldp.org/LDP/abs/html/filearchiv.html#DIFFERR2)). |
| `126`            | Command invoked cannot execute                               | /dev/null                   | Permission problem or command is not an executable           |
| `127`            | "command not found"                                          | illegal_command             | Possible problem with `$PATH` or a typo                      |
| `128`            | Invalid argument to [exit](https://tldp.org/LDP/abs/html/exit-status.html#EXITCOMMANDREF) | exit 3.14159                | **exit** takes only integer args in the range 0 - 255 (see first footnote) |
| `128+n`          | Fatal error signal "n"                                       | *kill -9* `$PPID` of script | `**$?**` returns 137 (128 + 9)                               |
| `130`            | Script terminated by Control-C                               | *Ctl-C*                     | Control-C is fatal error signal 2, (130 = 128 + 2, see above) |
| `255*`           | Exit status out of range                                     | exit -1                     | **exit** takes only integer args in the range 0 - 255        |

- 状态码需在0 - 255之间。0表示正常退出。
- 若因外界中断导致程序退出，则状态码区间为129 - 255。例如，操作系统给程序发送中断信号 kill -9 或ctrl+c，导致程序状态变为 SIGKILL 或 SIGINT。
- 通常因程序自身原因导致的异常退出，状态码区间在1 - 128。
- 在某些场景下，也允许程序设置使用129 - 255区间的状态码。
- 若指定的退出状态码不在0 - 255之间（例如，设置 exit(-1)），此时将会自动执行转换，最终呈现的状态码仍会在0 - 255之间。



### Pod异常状态的常见原因

1. Pod 一直处于 ContainerCreating 或Waiting 状态
   - Pod 配置错误
   - 挂载 Volume 失败
   - 磁盘空间不足
   - 节点内存碎片化
   - Limit 设置过小或单位错误
   - 拉取镜像失败
   - CNI 网络错误
   - controller-manager 异常
   - 安装 docker 时未完全删除旧版本
   - 存在同名容器
2. Pod 一直处于 ImagePullBackOff 状态
   - HTTP 类型 Registry 地址未加入 insecure-registry
   - HTTPS 自签发类型 Registry CA 证书未添加至节点
   - 私有镜像仓库认证失败
   - 镜像文件损坏镜像
   - 拉取超时镜像不存在
3. Pod 一直处于 Pending 状态
   - 节点资源不足不满足 
   - nodeSelector 与 affinity
   - Node 存在 Pod 没有容忍的污点
   - 低版本 kube-scheduler 的 bug
   - kube-scheduler 未正常运行
   - 驱逐后其他可用节点与当前节点的有状态应用不在相同可用区
4. Pod 一直处于 Terminating 状态
   - 磁盘空间不足
   - 存在 “i” 文件属性
   - Docker 17 版本 bug存在 Finalizers
   - 低版本 kubelet list-watch 的 bug
   - Dockerd 与 containerd 状态不同步
   - Daemonset Controller Bug
5. Pod 健康检查失败
   - 健康检查配置不合理
   - 节点负载过高
   - 容器进程被木马进程停止
   - 容器内进程端口监听故障
   - SYN backlog 设置过小
6. Pod 处于 CrashLoopBackOff 状态
   - 容器进程主动退出
   - 系统 OOM
   - cgroup OOM
   - 节点内存碎片化
   - 健康检查失败
7. 容器进程主动退出
   - DNS 无法解析
   - 程序配置有误

> https://cloud.tencent.com/document/product/457/42945

### istio 端到端请求处理流程

![image-20210224134423289](/assets/images/2021/study/image-20210224134423289.png)