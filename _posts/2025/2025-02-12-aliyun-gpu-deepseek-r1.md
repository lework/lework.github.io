---
layout: post
title: 'é˜¿é‡Œäº‘GPUæœåŠ¡å™¨éƒ¨ç½² DeepSeek R1 æ·±åº¦æ€è€ƒæ¨¡å‹'
date: '2025-02-12 20:00'
category: å¤§æ¨¡å‹
tags: é˜¿é‡Œäº‘ GPU DeepSeek
author: lework
---
* content
{:toc}

> æœ¬æ–‡ä»‹ç»å¦‚ä½•åœ¨é˜¿é‡Œäº‘ GPU æœåŠ¡å™¨ä¸Šéƒ¨ç½² DeepSeek R1 æ·±åº¦æ€è€ƒæ¨¡å‹ã€‚

{% raw %}

## æ–¹æ¡ˆè¯´æ˜

ç›®å‰éƒ¨ç½²æ¨¡å‹çš„æ–¹å¼æœ‰å¾ˆå¤šç§ï¼Œæ¯”å¦‚ Dockerã€Kubernetesã€Ollamaã€vLLM ç­‰ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ Ollama + DeepSeek ã€‚

**Ollama**

[Ollama](https://ollama.com/)Â  æ˜¯ä¸€ä¸ªè¿è¡Œå¤§æ¨¡å‹çš„å·¥å…·ï¼Œå¯ä»¥çœ‹æˆæ˜¯å¤§æ¨¡å‹é¢†åŸŸçš„ Dockerï¼Œå¯ä»¥ä¸‹è½½æ‰€éœ€çš„å¤§æ¨¡å‹å¹¶æš´éœ² Ollama APIï¼Œæå¤§çš„ç®€åŒ–äº†å¤§æ¨¡å‹çš„éƒ¨ç½²ã€‚

**DeepSeek**

[DeepSeek](https://www.deepseek.com/) ç³»åˆ—æ¨¡å‹æ˜¯ç”±æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸æ¨å‡ºçš„å¤§è¯­è¨€æ¨¡å‹ã€‚

DeepSeek-R1 æ¨¡å‹åŒ…å« 671B å‚æ•°ï¼Œæ¿€æ´» 37Bï¼Œåœ¨åè®­ç»ƒé˜¶æ®µå¤§è§„æ¨¡ä½¿ç”¨äº†å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œåœ¨ä»…æœ‰æå°‘æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæå¤§æå‡äº†æ¨¡å‹æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ•°å­¦ã€ä»£ç ã€è‡ªç„¶è¯­è¨€æ¨ç†ç­‰ä»»åŠ¡ä¸Šã€‚

DeepSeek-V3 ä¸º MoE æ¨¡å‹ï¼Œ671B å‚æ•°ï¼Œæ¿€æ´» 37Bï¼Œåœ¨ 14.8T Token ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œåœ¨é•¿æ–‡æœ¬ã€ä»£ç ã€æ•°å­¦ã€ç™¾ç§‘ã€ä¸­æ–‡èƒ½åŠ›ä¸Šè¡¨ç°ä¼˜ç§€ã€‚

DeepSeek-R1-Distill ç³»åˆ—æ¨¡å‹æ˜¯åŸºäºçŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œé€šè¿‡ä½¿ç”¨ DeepSeek-R1 ç”Ÿæˆçš„è®­ç»ƒæ ·æœ¬å¯¹ Qwenã€Llama ç­‰å¼€æºå¤§æ¨¡å‹è¿›è¡Œå¾®è°ƒè®­ç»ƒåï¼Œæ‰€å¾—åˆ°çš„å¢å¼ºå‹æ¨¡å‹ã€‚




**DeepSeek æ¨¡å‹é…ç½®è¦æ±‚**

| **æ¨¡å‹å‚æ•°è§„æ¨¡**   | **å…¸å‹ç”¨é€”**             | **CPU å»ºè®®**                              | **GPU å»ºè®®**                                    | **å†…å­˜å»ºè®® (RAM)** | **ç£ç›˜ç©ºé—´å»ºè®®**  | **é€‚ç”¨åœºæ™¯**                      |
| ------------------ | ------------------------ | ----------------------------------------- | ----------------------------------------------- | ------------------ | ----------------- | --------------------------------- |
| **1.5b (15 äº¿)**   | å°å‹æ¨ç†ã€è½»é‡çº§ä»»åŠ¡     | 4 æ ¸ä»¥ä¸Š (Intel i5 / AMD Ryzen 5)         | å¯é€‰ï¼Œå…¥é—¨çº§ GPU (å¦‚ NVIDIA GTX 1650, 4GB æ˜¾å­˜) | 8GB                | 10GB ä»¥ä¸Š SSD     | å°å‹ NLP ä»»åŠ¡ã€æ–‡æœ¬ç”Ÿæˆã€ç®€å•åˆ†ç±» |
| **7b (70 äº¿)**     | ä¸­ç­‰æ¨ç†ã€é€šç”¨ä»»åŠ¡       | 6 æ ¸ä»¥ä¸Š (Intel i7 / AMD Ryzen 7)         | ä¸­ç«¯ GPU (å¦‚ NVIDIA RTX 3060, 12GB æ˜¾å­˜)        | 16GB               | 20GB ä»¥ä¸Š SSD     | ä¸­ç­‰è§„æ¨¡ NLPã€å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬åˆ†æ  |
| **14b (140 äº¿)**   | ä¸­å¤§å‹æ¨ç†ã€å¤æ‚ä»»åŠ¡     | 8 æ ¸ä»¥ä¸Š (Intel i9 / AMD Ryzen 9)         | é«˜ç«¯ GPU (å¦‚ NVIDIA RTX 3090, 24GB æ˜¾å­˜)        | 32GB               | 50GB ä»¥ä¸Š SSD     | å¤æ‚ NLPã€å¤šè½®å¯¹è¯ã€çŸ¥è¯†é—®ç­”      |
| **32b (320 äº¿)**   | å¤§å‹æ¨ç†ã€é«˜æ€§èƒ½ä»»åŠ¡     | 12 æ ¸ä»¥ä¸Š (Intel Xeon / AMD Threadripper) | é«˜æ€§èƒ½ GPU (å¦‚ NVIDIA A100, 40GB æ˜¾å­˜)          | 64GB               | 100GB ä»¥ä¸Š SSD    | å¤§è§„æ¨¡ NLPã€å¤šæ¨¡æ€ä»»åŠ¡ã€ç ”ç©¶ç”¨é€”  |
| **70b (700 äº¿)**   | è¶…å¤§è§„æ¨¡æ¨ç†ã€ç ”ç©¶ä»»åŠ¡   | 16 æ ¸ä»¥ä¸Š (æœåŠ¡å™¨çº§ CPU)                  | å¤š GPU å¹¶è¡Œ (å¦‚ 2x NVIDIA A100, 80GB æ˜¾å­˜)      | 128GB              | 200GB ä»¥ä¸Š SSD    | è¶…å¤§è§„æ¨¡æ¨¡å‹ã€ç ”ç©¶ã€ä¼ä¸šçº§åº”ç”¨    |
| **671b (6710 äº¿)** | è¶…å¤§è§„æ¨¡è®­ç»ƒã€ä¼ä¸šçº§ä»»åŠ¡ | æœåŠ¡å™¨çº§ CPU (å¦‚ AMD EPYC / Intel Xeon)   | å¤š GPU é›†ç¾¤ (å¦‚ 8x NVIDIA A100, 320GB æ˜¾å­˜)     | 256GB æˆ–æ›´é«˜       | 1TB ä»¥ä¸Š NVMe SSD | è¶…å¤§è§„æ¨¡è®­ç»ƒã€ä¼ä¸šçº§ AI å¹³å°      |

æˆ‘ä»¬æœ¬æ¬¡åªè¿è¡Œæ¨¡å‹ï¼Œåœ¨ é˜¿é‡Œäº‘ `24G` æ˜¾å­˜ä¸‹ï¼Œå¯ä»¥è¿è¡Œ `32bå‚æ•°` çš„æ¨¡å‹

## è´­ä¹°æœåŠ¡å™¨

æœ¬æ¬¡ä½¿ç”¨çš„æ˜¯é˜¿é‡Œäº‘çš„ GPU æœåŠ¡å™¨ï¼Œè§„æ ¼å¦‚ä¸‹ï¼š

- å®ä¾‹è§„æ ¼: `ecs.gn7i-c16g1.4xlarge`
- æ“ä½œç³»ç»Ÿ: `Alibaba Cloud Linux 3.2104 LTS 64ä½`
- GPU: `NVIDIA Tesla A10 `
- CPU: `16 æ ¸(vCPU)`
- å†…å­˜: `60 GiB`
- ç¡¬ç›˜:
  - ç³»ç»Ÿç›˜: `40 GiB`
  - æ•°æ®ç›˜: `500 GiB`
- é…ç½®è´¹ç”¨ï¼š`ï¿¥5369.81`

æ›´å¤š ECS è§„æ ¼è¯·å‚è€ƒï¼š[ECS å®ä¾‹è§„æ ¼å¯è´­ä¹°åœ°åŸŸæ€»è§ˆ](https://ecs-buy.aliyun.com/instanceTypes#/instanceTypeByRegion)

## å®‰è£…é©±åŠ¨

1. å®‰è£…ç³»ç»Ÿå†…æ ¸å¤´æ–‡ä»¶

```bash
yum install -y kernel-devel-$(uname -r) kernel-headers-$(uname -r)
```

2. å®‰è£… NVIDIA é©±åŠ¨

```bash
wget https://cn.download.nvidia.com/tesla/470.161.03/NVIDIA-Linux-x86_64-470.161.03.run
chmod +x NVIDIA-Linux-x86_64-470.161.03.run
sh NVIDIA-Linux-x86_64-470.161.03.run
```

3. éªŒè¯ gpu é©±åŠ¨æ˜¯å¦å®‰è£…æˆåŠŸ

```bash
# nvidia-smi
Thu Feb 12 19:17:52 2025
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A10          Off  | 00000000:00:08.0 Off |                    0 |
|  0%   29C    P8    17W / 150W |      2MiB / 22731MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒé˜¿é‡Œäº‘å®˜æ–¹æ–‡æ¡£ï¼š[å®‰è£… GPU é©±åŠ¨]()

## å®‰è£… ollama

```bash
mkdir -p /data/ollama && cd /data/ollama
wget https://ollama.com/install.sh

# ä¸ºäº†åŠ é€Ÿä¸‹è½½ï¼Œå¯ä»¥ä½¿ç”¨ä»£ç†
sed -i 's#https://ollama.com/download#https://gh-proxy.com/github.com/ollama/ollama/releases/download/v0.5.8#g' install.sh

# ä¿®æ”¹å®¶ç›®å½•, dataç›®å½•æ˜¯æ•°æ®ç›˜
sed -i 's#-U -m -d /usr/share/ollama ollama#-U -m -d /data/ollama ollama#g' install.sh

# å¢åŠ ollama systemdçš„ç¯å¢ƒå˜é‡
sed -i '/\[Service\]/a\EnvironmentFile=/data/ollama/env' install.sh

cat > /data/ollama/env <<EOF
OLLAMA_HOST=0.0.0.0:11434
OLLAMA_ORIGINS=*
EOF

chmod +x install.sh
./install.sh

# å®‰è£…å®Œæˆåï¼Œå¯ä»¥æŸ¥çœ‹ ollama çš„çŠ¶æ€
systemctl status ollama

```

## è¿è¡Œ DeepSeek æ¨¡å‹

ä¸‹è½½ [DeepSeek](https://ollama.com/library/deepseek-r1) æ¨¡å‹

```bash
ollama pull deepseek-r1:32b
```

è¿è¡Œæ¨¡å‹

```bash
# ollama run deepseek-r1:32b
>>> /set verbose
Set 'verbose' mode.
>>> ä½ å¥½ï¼Œç»™æˆ‘è®²ä¸ªå¯ç¬‘çš„ç¬‘è¯  
<think>
å¥½çš„ï¼Œç”¨æˆ·è®©æˆ‘è®²ä¸ªå¯ç¬‘çš„ç¬‘è¯ã€‚é¦–å…ˆï¼Œæˆ‘å¾—è€ƒè™‘ç¬‘è¯çš„ç±»å‹ï¼Œè¦é€‚åˆå¤§å¤šæ•°äººçš„å£å‘³ï¼Œä¸èƒ½å¤ªå†·åƒ»æˆ–è€…æœ‰å†’çŠ¯æ€§ã€‚åŠ¨ç‰©ç±»çš„ç¬‘è¯é€šå¸¸æ¯”è¾ƒå—æ¬¢è¿ï¼Œä¹Ÿæ¯”è¾ƒå®¹æ˜“è®©äººå‘ç¬‘ã€‚

ç„¶åï¼Œæˆ‘éœ€è¦æƒ³ä¸€ä¸ªæœ‰è¶£çš„åœºæ™¯ã€‚æµ·æ»©æ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒç»™äººä¸€ç§è½»æ¾æ„‰å¿«çš„æ„Ÿè§‰ã€‚æ¥ä¸‹æ¥ï¼Œç¡®å®šè§’è‰²ï¼Œæµ·é¸¥å’ŒèƒèŸ¹éƒ½æ˜¯å¸¸è§çš„æµ·æ´‹ç”Ÿç‰©ï¼Œå®¹æ˜“è®©äººè”æƒ³åˆ°å®ƒä»¬çš„ç‰¹ç‚¹ã€‚

æ¥ä¸‹æ¥ï¼Œæ„æ€å¯¹è¯ã€‚æµ·é¸¥é—®é—®é¢˜ï¼ŒèƒèŸ¹å›ç­”ï¼Œå½¢æˆäº’åŠ¨ã€‚é—®é¢˜è¦æœ‰æ‚¬å¿µï¼Œæ¯”å¦‚ä¸ºä»€ä¹ˆä¸èƒ½æŠŠè¢œå­ç•™åœ¨æµ·æ»©ä¸Šã€‚è¿™æ ·çš„é—®é¢˜èƒ½å¼•èµ·å¬ä¼—çš„å¥½å¥‡å¿ƒï¼Œæƒ³çŸ¥é“ç­”æ¡ˆæ˜¯ä»€ä¹ˆã€‚

ç„¶åï¼Œè®¾è®¡ä¸€ä¸ªå‡ºäººæ„æ–™çš„è½¬æŠ˜ã€‚è¢œå­ä¼šè‡ªå·±èµ°ï¼Ÿè¿™å¬èµ·æ¥æœ‰ç‚¹å¥‡æ€ªï¼Œä½†å…¶å®æ˜¯å› ä¸ºèƒèŸ¹å–œæ¬¢åœ¨æ°´é‡Œæ´»åŠ¨ï¼Œæ‰€ä»¥è¢œå­ä¼šè¢«å¸¦å…¥æ°´ä¸­ï¼Œæ˜¾å¾—åƒæ˜¯è‡ªå·±èµ°äº†ã€‚è¿™ä¸ªè§£é‡Šæ—¢æœ‰è¶£åˆåˆç†ï¼Œè®©äººè§‰å¾—å¥½ç¬‘ã€‚

æœ€åï¼ŒåŠ ä¸Šä¸€å¥è°ƒä¾ƒçš„è¯ï¼Œæ¯”å¦‚â€œèŸ¹æ€»â€è¿™æ ·ç§°å‘¼ï¼Œå¢åŠ äº²åˆ‡æ„Ÿå’Œå¹½é»˜æ„Ÿï¼Œè®©ç”¨æˆ·æ„Ÿè§‰æ›´è‡ªç„¶ï¼Œæ›´å®¹æ˜“å‘ç¬‘ã€‚

æ•´ä½“ä¸Šï¼Œç¬‘è¯çš„ç»“æ„æ¸…æ™°ï¼Œæœ‰å¼€å¤´ã€å‘å±•å’Œç»“å°¾ï¼Œç¬¦åˆä¸€èˆ¬çš„å¹½é»˜æ¨¡å¼ï¼Œåº”è¯¥èƒ½å¼•èµ·ç”¨æˆ·çš„ç¬‘å£°ã€‚
</think>

å½“ç„¶å¯ä»¥ï¼è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„ç¬‘è¯ï¼š

æœ‰ä¸€å¤©ï¼Œä¸€åªæµ·é¸¥é—®ä¸€åªèƒèŸ¹ï¼šâ€œä¸ºä»€ä¹ˆä½ ä¸èƒ½æŠŠè¢œå­ç•™åœ¨æµ·æ»©ä¸Šï¼Ÿâ€

èƒèŸ¹å›ç­”è¯´ï¼šâ€œå› ä¸ºå®ƒä»¬ä¼šè‡ªå·±èµ°ï¼â€

æµ·é¸¥æ„£äº†ä¸€ä¸‹ï¼Œè¯´ï¼šâ€œå“¦ï¼ŒåŸæ¥æ˜¯è¿™æ ·ï¼ä¸è¿‡â€¦â€¦ä½ çš„è¢œå­å‘¢ï¼Ÿâ€

èƒèŸ¹ä¸å¥½æ„æ€åœ°è¯´ï¼šâ€œæˆ‘è¿˜æ²¡å­¦ä¼šç©¿è¢œå­ã€‚â€

å“ˆå“ˆï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹å¥½ç¬‘ï¼ŸğŸ˜„

total duration:       16.75064966s
load duration:        14.872699ms
prompt eval count:    12 token(s)
prompt eval duration: 42ms
prompt eval rate:     285.71 tokens/s
eval count:           330 token(s)
eval duration:        16.693s
eval rate:            19.77 tokens/s

```

é€šè¿‡æ¥å£ä½¿ç”¨ DeepSeek

```bash
# curl http://localhost:11434/api/chat -d '{
  "model": "deepseek-r1:32b",
  "messages": [{ "role": "user", "content": "hi" }],
  "stream": false
}'
{"model":"deepseek-r1:32b","created_at":"2025-02-13T08:06:34.246236674Z","message":{"role":"assistant","content":"\u003cthink\u003e\n\n\u003c/think\u003e\n\nHello! How can I assist you today? ğŸ˜Š"},"done_reason":"stop","done":true,"total_duration":808218860,"load_duration":14494335,"prompt_eval_count":4,"prompt_eval_duration":29000000,"eval_count":16,"eval_duration":764000000}
```

**æ³¨æ„**: å¤–éƒ¨è®¿é—®æ—¶ï¼Œéœ€è¦åœ¨é˜¿é‡Œäº‘å®‰å…¨ç»„ä¸­å¼€æ”¾ `11434` ç«¯å£

æ›´å¤šçš„ ollama REST API è¯·å‚è€ƒï¼š[Ollama API](https://www.postman.com/postman-student-programs/ollama-api/documentation/suc47x8/ollama-rest-api)



**Tokenç”Ÿæˆå¯¹æ¯”**

ç”¨æˆ·è¾“å…¥ï¼š`ä½ å¥½ï¼Œç»™æˆ‘è®²ä¸ªå¯ç¬‘çš„ç¬‘è¯`

| deepseek-r1:14b                                              | deepseek-r1:32b                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| total duration:       16.497871632s<br/>load duration:        14.803653ms<br/>prompt eval count:    12 token(s)<br/>prompt eval duration: 574ms<br/>prompt eval rate:     20.91 tokens/s<br/>eval count:           620 token(s)<br/>eval duration:        15.907s<br/>eval rate:            38.98 tokens/s | total duration:       16.75064966s<br/>load duration:        14.872699ms<br/>prompt eval count:    12 token(s)<br/>prompt eval duration: 42ms<br/>prompt eval rate:     285.71 tokens/s<br/>eval count:           330 token(s)<br/>eval duration:        16.693s<br/>eval rate:            19.77 tokens/s |

ç½‘ç»œä¸Šåˆ†äº«çš„ä¸€äº› Token ç”Ÿæˆæ•°æ®

https://llm.aidatatools.com/results-linux.php 



## ç¤¾åŒºé›†æˆ

åœ¨æ”¾å¼€ ollama çš„ API è®¿é—®åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç¤¾åŒºé›†æˆï¼Œå¿«é€Ÿçš„ä½¿ç”¨ DeepSeek æ¨¡å‹ã€‚

**WEB é¡¹ç›®**

- [Open WebUI](https://github.com/open-webui/open-webui)
- [Lobe Chat](https://github.com/lobehub/lobe-chat)
- [LibreChat](https://github.com/danny-avila/LibreChat)
- [Dify.AI](https://github.com/langgenius/dify)
- [RAGFlow](https://github.com/infiniflow/ragflow)

**æ¡Œé¢é¡¹ç›®**

- [Chatbox](https://github.com/Bin-Huang/Chatbox)
- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)

{% endraw %}
